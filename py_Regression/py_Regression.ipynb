{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6836b400-86e9-4b99-984e-675c0d0cc8f9",
   "metadata": {},
   "source": [
    "# Linear Regression With scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4b78c4-9c79-45e5-a06b-9d066986b777",
   "metadata": {},
   "source": [
    "<b>Underfitting</b> occurs when a model can't accurately capture the dependencies among data, usually as a consequence of its own simplicity. It often yields a low R^2 with known data and bad generalization capabilities when applied with new data.\n",
    "\n",
    "<b>Overfitting</b> happens when a model learns both data dependencies and random fluctuations. In other words, a model learns the existing data too well. Complex models, which have many features or terms, are often prone to overfitting. When applied to known data, such models usually yield high ùëÖ¬≤. However, they often don‚Äôt generalize well and have significantly lower ùëÖ¬≤ when used with new data.\n",
    "\n",
    "- Mean Absolute error: The mean of the absolute value of the errors. This is the easiest of the metrics to understand since it's just average error.\n",
    "- Mean Squared Error (MSE): The mean o the squared error. It's more popular than Mean Absolute Error becauset he focus is geared more towards large errors. This is due to the squared term exponentially increasing large errors in comparison to smaller ones.\n",
    "- Root Mean Squared Error (RMSE): The square root of the MSE. \n",
    "- Coefficient of determination (R^2): Not an error, but rather a popular metric to measure the performance of your regression model. It represents how close the data points are to the fitted regression line. The higher the R-squared value, the better the model fits your data. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). You can use the .score() method to get this metric. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaddd61-717e-46ba-b6af-4f4a3ff48033",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"https://files.realpython.com/media/poly-reg.5790f47603d8.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ef46de-2259-4a0a-8fb5-b7b29f0dc5a7",
   "metadata": {},
   "source": [
    "<img src=\"https://files.realpython.com/media/fig-lin-reg.a506035b654a.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2707a6-33c0-47e2-92df-638e5c36678e",
   "metadata": {},
   "source": [
    "### Recommended Python Packges for LR: \n",
    "-  NumPy\n",
    "- Scikit-learn\n",
    "- Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "211a0e1a-2ea3-448c-a806-c60ca3ce74c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 1: Import libraries\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0da6743-cb95-4bc4-af35-773b177533ad",
   "metadata": {},
   "source": [
    "The fundamental data type of NumPy is the array type called numpy.ndarray, which is referenced here as array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e9d61a7-a3d8-42b2-a735-f425723c77c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 2: Provide the data\n",
    "#X must have one column and as many rows as necessary, specified by the .reshape(-1, 1)\n",
    "x = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1))\n",
    "y = np.array([5, 20, 14, 32, 22, 38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91e83b33-e97b-4ef1-98f8-f0b947edbb03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5]\n",
      " [15]\n",
      " [25]\n",
      " [35]\n",
      " [45]\n",
      " [55]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b38701ad-7ca6-4523-9b8c-ca14f35fa4b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 20 14 32 22 38]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fc3d919-0d7a-4852-a1ec-306491b3547f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 3: Create a model and fit it\n",
    "#.fit() calculates the optimal value of the weights b0 and b1, using the existing input and output, x and y, as the arguments.\n",
    "#.fit() fits the model\n",
    "#.fit() returns self, which is the variable model itself. \n",
    "model = LinearRegression()\n",
    "model.fit(x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "378751f0-d7f9-46ae-9956-a4cbb4842471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#OR all in one line\n",
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f99b5-4630-45ee-9885-48ae89613c3f",
   "metadata": {},
   "source": [
    "This statement creates the variable model as an instance of LinearRegression. You can provide several optional parameters to LinearRegression:\n",
    "\n",
    "- <b>fit_intercept</b> is a Boolean that, if True, decides to calculate the intercept ùëè‚ÇÄ or, if False, considers it equal to zero. It defaults to True.\n",
    "- <b>normalize</b> is a Boolean that, if True, decides to normalize the input variables. It defaults to False, in which case it doesn‚Äôt normalize the input variables.\n",
    "- <b>copy_X</b> is a Boolean that decides whether to copy (True) or overwrite the input variables (False). It‚Äôs True by default.\n",
    "- <b>n_jobs</b> is either an integer or None. It represents the number of jobs used in parallel computation. It defaults to None, which usually means one job. -1 means to use all available processors.\n",
    "\n",
    "Your model as defined above uses the default values for all parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9fd957-3a98-4db5-b81d-b21d2b25c441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 4: Get results\n",
    "\n",
    "#Get R^2, the coefficient of determination\n",
    "r_sq = model.score(x,y)\n",
    "\n",
    "#Get b0, the intercept, and b1, the slope\n",
    "b0 = model.intercept_\n",
    "slope = model.coef_\n",
    "\n",
    "print(r_sq)\n",
    "print(b0)\n",
    "print(slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b9952-9b6f-405d-9a47-f05cce7eb381",
   "metadata": {},
   "source": [
    "Note: By convention, in scikit-learn, a trailing underscore (i.e. intercept_) indicates an attribute that is estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a31cebf-58db-4724-9eb9-b5f275ec8c10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: 5.633333333333329\n",
      "slope: [0.54]\n"
     ]
    }
   ],
   "source": [
    "#Print R^2, the coefficient of determination, and b0, the intercept, and b1, the coefficeint\n",
    "print(f'intercept: {model.intercept_}')\n",
    "print(f\"slope: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e538cf8e-d61f-451b-a7cd-08e64d2f3f38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted response: \n",
      "[ 8.33333333 13.73333333 19.13333333 24.53333333 29.93333333 35.33333333]\n"
     ]
    }
   ],
   "source": [
    "#Once you have your model, you can use it for predictions with either existing or new data. To obtain the predicted response, use .predict()\n",
    "y_pred = model.predict(x)\n",
    "print(f\"predicted response: \\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf348ebf-2277-4095-8912-181e4379f285",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted response: \n",
      "[[ 8.33333333]\n",
      " [13.73333333]\n",
      " [19.13333333]\n",
      " [24.53333333]\n",
      " [29.93333333]\n",
      " [35.33333333]]\n"
     ]
    }
   ],
   "source": [
    "#Same thing. below instead of .predict(x)\n",
    "y_pred = model.intercept_ + model.coef_ * x\n",
    "print(f'predicted response: \\n{y_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a5e5fd-86a9-44ce-b00d-a370ed7da3eb",
   "metadata": {},
   "source": [
    "In practice, regression models are often applied for forecasts. This means that you can use fitted models to calculate the outputs based on new inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43038899-74e6-45ce-bc19-ed5c1912ba08",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d2f4ba-d228-4d8f-bd0b-add90da4047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "#Viewing how linear a relationjship is\n",
    "plt.scatter(cdf.UELCONSUMPTION, cdf.C02EMISSIONS, color='blue')\n",
    "plt.xolabel('FUEL CONSUMPTION')\n",
    "plt.ylabel('Emission')\n",
    "plt.show()\n",
    "\n",
    "#Creating a train and test dataset\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = cdf[msk]\n",
    "test = cdf[~msk]\n",
    "\n",
    "#Simple regression model\n",
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "train_x = np.asanyarray(train[['ENGINE SIZE']])\n",
    "train_y = np.asanyarray(train[['C02EMISSIONS']])\n",
    "regr.fit(train_x, train_y)\n",
    "print('Coefficients: ', regr.coef_)\n",
    "print('Intercept: ', regr.intercept_)\n",
    "\n",
    "#Plot the fit line over the data\n",
    "plt.scatter(train.ENGINESIZE, train.C02EMISSIONS, color='blue')\n",
    "plt.plot(train_x, regr.coef_[0][0]*train_x + regr.intercept_[0], '-r')\n",
    "plt.xlabel('Engine size')\n",
    "plt.ylabel('Emission')\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "test_x = np.asanyarray(test[['ENGINESIZE']])\n",
    "test_y = np.asanyarray(test[['C02EMISSIONS']])\n",
    "test_y_ = regr.predict(test_x)\n",
    "print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_ - test_y))\n",
    "print(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_ - test_y) ** 2))\n",
    "print(\"R2-score: %.2f\" % r2_score(test_y, test_y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43623f8-ee87-4a46-a3e5-3aacf55e7cb4",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression With scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a2534-4052-49d5-bd4d-20881b9ba73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "- Multivarite regression, or multipl elinear regression, is a case of linear regression with two or more independent variables. \n",
    "- It represents a regression plane in a three dimensional space. The goal of regression is to determine the values oft he weights b0, b1, and b2, such  that this plane is as close as possible to the actual responses, while yieldin the minimal SSR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bca58660-5a33-4d43-9501-768abb0544a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1]\n",
      " [ 5  1]\n",
      " [15  2]\n",
      " [25  5]\n",
      " [35 11]\n",
      " [45 15]\n",
      " [55 34]\n",
      " [60 35]]\n",
      "[ 4  5 20 14 32 22 38 43]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = np.array(x), np.array(y)\n",
    "print(x)\n",
    "print(y)\n",
    "type(x)\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0a73c80-3ba0-4d17-b7df-30b83acc85c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a model and fit it\n",
    "model = LinearRegression().fit(x, y)\n",
    "\n",
    "#Obtain the properties of the model the way as in the case of simple linear regression\n",
    "r_sq = model.score(x, y)\n",
    "print(f'coefficient of determination: {r_sq}')\n",
    "print(f'intercept: {model.intercept_}')\n",
    "print(f'coefficients: {model.coef_}')\n",
    "\n",
    "#Predicting a response\n",
    "y_pred = model.predict(x)\n",
    "print(f\"predicted response:\\n{y_pred}\")\n",
    "\n",
    "#obtain the response with .predict(), or the below:\n",
    "y_pred = model.intercept_ + np.sum(model.coef_ * x, axis=1)\n",
    "print(f\"predicted response:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b8e79-6923-4109-a8f7-b7c2eeb7227a",
   "metadata": {},
   "source": [
    "Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b31bc-dee4-4467-a047-f738a1234b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple linear regression\n",
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "x = np.asanyarray(train[['ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB']])\n",
    "y = np.asanyarray(train[['CO2EMISSIONS']])\n",
    "regr.fit (x, y)\n",
    "# The coefficients\n",
    "print ('Coefficients: ', regr.coef_)\n",
    "\n",
    "#Predictions\n",
    "y_hat= regr.predict(test[['ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB']])\n",
    "x = np.asanyarray(test[['ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB']])\n",
    "y = np.asanyarray(test[['CO2EMISSIONS']])\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((y_hat - y) ** 2))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e64d83e-9db7-4059-b02e-6fb262ba6162",
   "metadata": {},
   "source": [
    "# Polynomial Regression With scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b7c0fd-6f1b-432d-bb47-26f4b4e9615d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Implementing polynomial regression with scikit-learn is very similar to linear regression. There's only one extrta step: you need to transform the array of inputs to include nonlinear terms such as x^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73bc8bd1-b542-4a88-a1f1-4232853aaec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5]\n",
      " [15]\n",
      " [25]\n",
      " [35]\n",
      " [45]\n",
      " [55]]\n",
      "[15 11  2  8 25 32]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#Reshape is used here because we need a two-dimensional array\n",
    "x = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1))\n",
    "y = np.array([15, 11, 2, 8, 25, 32])\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0120a7ec-8c8d-47a8-ab80-b5c3218ac5bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We now need to include x^2, so we need to transform the input array x to contain any aditional column swith the values of x^2.\n",
    "#Class PolynomialFeatures is very convenient for this purpose\n",
    "\n",
    "#We use transformer to transform input x\n",
    "#Degree = degree of the polynomial regression function. Interaction_only is a boolean that decides whether to include only interaction features or all features.\n",
    "#include_bias is a voolean that decides whether to include the bais, or intercept, column of 1 values or not. \n",
    "transformer = PolynomialFeatures(degree = 2, include_bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb4ce3-3510-4703-9aa4-79e10baf6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we must fit the instance of the PolynomialFeatures variable, the transformer variable\n",
    "transformer.fit(x)\n",
    "\n",
    "#Now we create a new, modifid input array. \n",
    "x_ = transformer.transform(x)\n",
    "\n",
    "#We can also use fit_transform to replace the three previous statements with only one\n",
    "x_ = PolynomialFeatures(degree = 2, include_bias = False).fit_transform(x)\n",
    "\n",
    "#The modified input array x_ contians two columns: one with the original inputs, and the other with their sqauares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe3039a-1af7-4efc-8fe9-6618e2233e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, create a model and fit it\n",
    "model = LinearRegression().fit(x_, y)\n",
    "\n",
    "#Check the results\n",
    "r_sq = model.score(x_, y) \n",
    "print(f\"coefficient of determination: {r_sq}\")\n",
    "print(f\"intercept: {model.intercept_}\")\n",
    "print(f\"coefficients: {model.coef_}\")\n",
    "\n",
    "#Finally, we predict a response\n",
    "y_pred = model.predict(x_)\n",
    "print(f'predicted response: \\n{y_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d70fdf-fa09-4e6d-89be-db8a162b8be8",
   "metadata": {},
   "source": [
    "# Advanced Linear Regression with statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd591df-2383-4c79-8d94-9ea21a0be696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "\n",
    "x,y = np.array(x), np.array(y)\n",
    "\n",
    "#You need to addt he column of ones to he inputs if you want statsmodels to calculate the intercept b0. It doesn't take b0 into accoun by default.\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "#The regression model based on ordinary least squares is an instance of the class statsmodels.regression.linear_model.ols\n",
    "model = sm.OLS(y, x)\n",
    "\n",
    "#Once your model is created, you can apply .fit() on it\n",
    "results = model.fit()\n",
    "\n",
    "#By calling fit, you obtain the variable results, which is an instanece of the class statsmodels.regression.linear_model.regressionResultsWrapper. \n",
    "#This object holds a lot of information about the regression model. \n",
    "\n",
    "#You can call .summaryh() to get the table witht he results of linear regressikon\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb056c-fc0d-4b68-84fe-ee63fbcdea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"coefficient of determination: {results.rsquared}\")\n",
    "print(f\"adjusted coefficient of determination: {results.rsquared_adj}\")\n",
    "print(f\"regression coefficients: {results.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7acf7b2-e42e-4cce-92ec-574cdb074b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict a response\n",
    "print(f\"predicted response:\\n{results.fittedvalues}\")\n",
    "print(f\"predicted response:\\n{results.predict(x)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
